{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w aɪ t\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "import torch\n",
    "from itertools import groupby\n",
    "from datasets import load_dataset\n",
    "\n",
    "def decode_phonemes(\n",
    "    ids: torch.Tensor, processor: Wav2Vec2Processor, ignore_stress: bool = False\n",
    ") -> str:\n",
    "    \"\"\"CTC-like decoding. First removes consecutive duplicates, then removes special tokens.\"\"\"\n",
    "    # removes consecutive duplicates\n",
    "    ids = [id_ for id_, _ in groupby(ids)]\n",
    "\n",
    "    special_token_ids = processor.tokenizer.all_special_ids + [\n",
    "        processor.tokenizer.word_delimiter_token_id\n",
    "    ]\n",
    "    # converts id to token, skipping special tokens\n",
    "    phonemes = [processor.decode(id_) for id_ in ids if id_ not in special_token_ids]\n",
    "\n",
    "    # joins phonemes\n",
    "    prediction = \" \".join(phonemes)\n",
    "\n",
    "    # whether to ignore IPA stress marks\n",
    "    if ignore_stress == True:\n",
    "        prediction = prediction.replace(\"ˈ\", \"\").replace(\"ˌ\", \"\")\n",
    "\n",
    "    return prediction\n",
    "\n",
    "checkpoint = \"bookbot/wav2vec2-ljspeech-gruut\"\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(checkpoint)\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "sr = processor.feature_extractor.sampling_rate\n",
    "\n",
    "# # load dummy dataset and read soundfiles\n",
    "# ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "# audio_array = ds[0][\"audio\"][\"array\"]\n",
    "\n",
    "# or, read a single audio file\n",
    "audio_array, _ = librosa.load(\"data/test/wight.wav\", sr=sr)\n",
    "\n",
    "inputs = processor(audio_array, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs[\"input_values\"]).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "prediction = decode_phonemes(predicted_ids[0], processor, ignore_stress=True)\n",
    "# => should give 'b ɪ k ʌ z j u ɚ z s l i p ɪ ŋ ɪ n s t ɛ d ə v k ɔ ŋ k ɚ ɪ ŋ ð ə l ʌ v l i ɹ z p ɹ ɪ n s ə s h æ z b ɪ k ʌ m ə v f ɪ t ə l w ɪ θ n b oʊ p ɹ ə ʃ æ ɡ i s ɪ t s ð ɛ ɹ ə k u ɪ ŋ d ʌ v'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word bank\n",
    "phoneme_bank = {\n",
    "    \"run\": \"ɹ ʌ n\",\n",
    "    \"rope\": \"ɹ ə ʊ p\",\n",
    "    \"rabbit\": \"ˈɹ æ b ɪ t\",\n",
    "    \"rocket \": \"ˈr ɒ k ɪ t\",\n",
    "    \"carrot\": \"ˈk æ ɹ ə t\",\n",
    "    \"berry\": \"ˈb ɛ ɹ i\",\n",
    "    \"pirate\": \"ˈp a ɪ ɹ ə t\",\n",
    "    \"airplane\": \"ˈe ə p l e ɪ n\",\n",
    "    \"car\": \"k ɑː\",\n",
    "    \"door\": \"d ɔː\",\n",
    "    \"tiger\": \"ˈt aɪ ɡ ə\",\n",
    "    \"hammer\": \"ˈh æ m ə\", \n",
    "    \"right\": \"ɹ aɪ t\"\n",
    "}\n",
    "\n",
    "# splitting entire strings into indivudal phonemes for comparison later\n",
    "phoneme_bank_split = {word: phonemes.split() for word, phonemes in phoneme_bank.items()}\n",
    "\n",
    "# Print the new phoneme bank to check the format\n",
    "# print(phoneme_bank_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar word is 'right' with a distance of 1\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein \n",
    "\n",
    "def find_most_similar_word(prediction, phoneme_bank_split):\n",
    "    prediction_phonemes = prediction.split()\n",
    "    most_similar_word = None\n",
    "    min_distance = float('inf')  \n",
    "\n",
    "    for word, phonemes in phoneme_bank_split.items():\n",
    "        distance = Levenshtein.distance(\" \".join(prediction_phonemes), \" \".join(phonemes))\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            most_similar_word = word\n",
    "\n",
    "    return most_similar_word, min_distance, prediction_phonemes\n",
    "\n",
    "word, distance, prediction_phonemes = find_most_similar_word(prediction, phoneme_bank_split)\n",
    "print(f\"The most similar word is '{word}' with a distance of {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned Prediction:  w aɪ t\n",
      "Aligned Correct:     ɹ aɪ t\n",
      "Extra Phonemes:      w\n",
      "Missing Phonemes:    ɹ\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def align_and_compare(prediction, correct):\n",
    "    matcher = SequenceMatcher(None, prediction, correct)\n",
    "    extra_phonemes = []\n",
    "    missing_phonemes = []\n",
    "    aligned_prediction = []\n",
    "    aligned_correct = []\n",
    "\n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag == \"equal\":\n",
    "            aligned_prediction.extend(prediction[i1:i2])\n",
    "            aligned_correct.extend(correct[j1:j2])\n",
    "        elif tag == \"replace\":\n",
    "            # substitution mismatch does not relate to length\n",
    "            aligned_prediction.extend(prediction[i1:i2])\n",
    "            aligned_correct.extend(correct[j1:j2])\n",
    "            extra_phonemes.extend(prediction[i1:i2])\n",
    "            missing_phonemes.extend(correct[j1:j2])\n",
    "        elif tag == \"delete\":\n",
    "            # extra phonemes\n",
    "            aligned_prediction.extend(prediction[i1:i2])\n",
    "            aligned_correct.extend([\"-\"] * (i2 - i1))  \n",
    "            extra_phonemes.extend(prediction[i1:i2])\n",
    "        elif tag == \"insert\":\n",
    "            # missing phonemes (ineherently occurs for any mismatch)\n",
    "            aligned_prediction.extend([\"-\"] * (j2 - j1))  \n",
    "            aligned_correct.extend(correct[j1:j2])\n",
    "            missing_phonemes.extend(correct[j1:j2])\n",
    "\n",
    "    print(\"Aligned Prediction: \", \" \".join(aligned_prediction))\n",
    "    print(\"Aligned Correct:    \", \" \".join(aligned_correct))\n",
    "    print(\"Extra Phonemes:     \", \" \".join(extra_phonemes))\n",
    "    print(\"Missing Phonemes:   \", \" \".join(missing_phonemes))\n",
    "\n",
    "    return extra_phonemes, missing_phonemes\n",
    "\n",
    "correct_phonemes = phoneme_bank_split[word]\n",
    "extra_phonemes, target_phonemes = align_and_compare(prediction_phonemes, correct_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Extra phoneme 'w': Try starting with closed lips. Then lift your lips just slightly apart without making an 'o' shape. Focus on keeping your teeth close together with your tongue tip slightly hovering.\"]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feedback bank\n",
    "feedback_bank = {\n",
    "    'w': \"Try starting with closed lips. Then lift your lips just slightly apart without making an 'o' shape. Focus on keeping your teeth close together with your tongue tip slightly hovering.\",\n",
    "    'l': \"Try lowering the tip of your tongue and keeping it stationary. Make the sound only moving your jaw\",\n",
    "    'ʌ': \"Raise the back of your tongue and produce more tension in the throat for /r/.\",\n",
    "    # Add more phoneme-specific feedback as needed\n",
    "}\n",
    "\n",
    "def generate_feedback(extra_phonemes):\n",
    "    feedback = []\n",
    "\n",
    "    # Feedback for extra phonemes\n",
    "    for phoneme in extra_phonemes:\n",
    "        if phoneme in feedback_bank:\n",
    "            feedback.append(f\"Extra phoneme '{phoneme}': {feedback_bank[phoneme]}\")\n",
    "        else:\n",
    "            feedback.append(f\"Extra phoneme '{phoneme}': No specific feedback available.\")\n",
    "\n",
    "    return feedback\n",
    "\n",
    "generate_feedback(extra_phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ACCESS A SPECIFIC WORD IN BANK AND MATCH ENTIRE STRING OF BOTH (NO NUANCES)\n",
    "# word = \"right\"\n",
    "# phonemes = phoneme_bank[word]\n",
    "\n",
    "# # Print the phoneme sequence\n",
    "# print(f\"The phonemes for '{word}' are: {phonemes}\")\n",
    "\n",
    "# if prediction == phonemes:\n",
    "#     print(\"The predictions matches the word bank\")\n",
    "# else:\n",
    "#     print(\"The prediction does NOT match the word\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # HANDLE CASES WHERE LENGTHS DIFFER BUT ONLY BASED ON LENGTH (ONLY ENDING PHONEMES CONSIDERED, NO NUANCES)\n",
    "# if len(prediction_phonemes) != len(correct_phonemes):\n",
    "#     print(\"Prediction and target phonemes have different lengths.\")\n",
    "#     extra_phonemes = prediction_phonemes[len(correct_phonemes):]\n",
    "#     if extra_phonemes:\n",
    "#         print(f\"Extra phonemes in prediction: {' '.join(extra_phonemes)}\")\n",
    "#     missing_phonemes = correct_phonemes[len(prediction_phonemes):]\n",
    "#     if missing_phonemes:\n",
    "#         print(f\"Missing phonemes in prediction: {' '.join(missing_phonemes)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # CHECKING FOR EXTRA / MISSING PHONEMES WHEN LENGTHS DIFFER (ANY POSITION MISMATCH) BUT DOESN'T CONSIDER ALIGNMENT OF CORRECT PHONEMES AFTER MISMATCH\n",
    "# # Check for phonemes that are extra or missing within the sequence\n",
    "# extra_phonemes = []\n",
    "# missing_phonemes = []\n",
    "\n",
    "# # Iterate over both lists up to the length of the shorter one to find mismatches\n",
    "# for i in range(min(len(prediction_phonemes), len(correct_phonemes))):\n",
    "#     if prediction_phonemes[i] != correct_phonemes[i]:\n",
    "#         extra_phonemes.append(prediction_phonemes[i])\n",
    "#         missing_phonemes.append(correct_phonemes[i])\n",
    "\n",
    "# # If one list is longer than the other, add remaining phonemes\n",
    "# if len(prediction_phonemes) > len(correct_phonemes):\n",
    "#     extra_phonemes.extend(prediction_phonemes[len(correct_phonemes):])\n",
    "# elif len(correct_phonemes) > len(prediction_phonemes):\n",
    "#     missing_phonemes.extend(correct_phonemes[len(prediction_phonemes):])\n",
    "\n",
    "# # Print results\n",
    "# if extra_phonemes:\n",
    "#     print(f\"Extra phonemes in prediction: {' '.join(extra_phonemes)}\")\n",
    "# if missing_phonemes:\n",
    "#     print(f\"Missing phonemes in prediction: {' '.join(missing_phonemes)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # FINDING MISMATCHES BETWEEN PREDICTION AND CORRECT PHONEMES (WORKS PERFECT FOR STRINGS SAME LENGTH)\n",
    "# # Phoneme string for the word in the word bank\n",
    "# correct_phonemes = phoneme_bank_split[word]\n",
    "\n",
    "# # Compare phoneme by phoneme\n",
    "# mismatches = []\n",
    "# for i, (predicted, correct) in enumerate(zip(prediction_phonemes, correct_phonemes)):\n",
    "#     if predicted != correct:\n",
    "#         mismatches.append((i, predicted, correct))\n",
    "\n",
    "# # Report mismatches\n",
    "# if not mismatches:\n",
    "#     print(\"The pronounciation matches exactly!\")\n",
    "# else:\n",
    "#     print(\"Mismatch found!\")\n",
    "#     for i, predicted, correct in mismatches:\n",
    "#         print(f\"Position {i}: Predicted '{predicted}', Expected '{correct}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
